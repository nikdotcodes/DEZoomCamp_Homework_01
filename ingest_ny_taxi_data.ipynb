{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation for homework"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1.5.2'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "So first things first is to read the csv into pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n0         2  2018-12-21 15:17:29   2018-12-21 15:18:57                  N   \n1         2  2019-01-01 00:10:16   2019-01-01 00:16:32                  N   \n2         2  2019-01-01 00:27:11   2019-01-01 00:31:38                  N   \n3         2  2019-01-01 00:46:20   2019-01-01 01:04:54                  N   \n4         2  2019-01-01 00:19:06   2019-01-01 00:39:43                  N   \n\n   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n0           1           264           264                5           0.00   \n1           1            97            49                2           0.86   \n2           1            49           189                2           0.66   \n3           1           189            17                2           2.68   \n4           1            82           258                1           4.53   \n\n   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n0          3.0    0.5      0.5        0.00           0.0        NaN   \n1          6.0    0.5      0.5        0.00           0.0        NaN   \n2          4.5    0.5      0.5        0.00           0.0        NaN   \n3         13.5    0.5      0.5        2.96           0.0        NaN   \n4         18.0    0.5      0.5        0.00           0.0        NaN   \n\n   improvement_surcharge  total_amount  payment_type  trip_type  \\\n0                    0.3          4.30             2          1   \n1                    0.3          7.30             2          1   \n2                    0.3          5.80             1          1   \n3                    0.3         19.71             1          1   \n4                    0.3         19.30             2          1   \n\n   congestion_surcharge  \n0                   NaN  \n1                   NaN  \n2                   NaN  \n3                   NaN  \n4                   NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VendorID</th>\n      <th>lpep_pickup_datetime</th>\n      <th>lpep_dropoff_datetime</th>\n      <th>store_and_fwd_flag</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2018-12-21 15:17:29</td>\n      <td>2018-12-21 15:18:57</td>\n      <td>N</td>\n      <td>1</td>\n      <td>264</td>\n      <td>264</td>\n      <td>5</td>\n      <td>0.00</td>\n      <td>3.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>4.30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2019-01-01 00:10:16</td>\n      <td>2019-01-01 00:16:32</td>\n      <td>N</td>\n      <td>1</td>\n      <td>97</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0.86</td>\n      <td>6.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>7.30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2019-01-01 00:27:11</td>\n      <td>2019-01-01 00:31:38</td>\n      <td>N</td>\n      <td>1</td>\n      <td>49</td>\n      <td>189</td>\n      <td>2</td>\n      <td>0.66</td>\n      <td>4.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>5.80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2019-01-01 00:46:20</td>\n      <td>2019-01-01 01:04:54</td>\n      <td>N</td>\n      <td>1</td>\n      <td>189</td>\n      <td>17</td>\n      <td>2</td>\n      <td>2.68</td>\n      <td>13.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>2.96</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>19.71</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2019-01-01 00:19:06</td>\n      <td>2019-01-01 00:39:43</td>\n      <td>N</td>\n      <td>1</td>\n      <td>82</td>\n      <td>258</td>\n      <td>1</td>\n      <td>4.53</td>\n      <td>18.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>19.30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data = pd.read_csv(\"data_in/green_tripdata_2019-01.csv\")\n",
    "taxi_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "            VendorID     RatecodeID   PULocationID   DOLocationID  \\\ncount  630918.000000  630918.000000  630918.000000  630918.000000   \nmean        1.851513       1.331461     109.731544     129.135265   \nstd         0.355582       1.099408      72.824598      76.854829   \nmin         1.000000       1.000000       1.000000       1.000000   \n25%         2.000000       1.000000      52.000000      62.000000   \n50%         2.000000       1.000000      82.000000     129.000000   \n75%         2.000000       1.000000     166.000000     193.000000   \nmax         2.000000       6.000000     265.000000     265.000000   \n\n       passenger_count  trip_distance    fare_amount          extra  \\\ncount    630918.000000  630918.000000  630918.000000  630918.000000   \nmean          1.318214       3.438878      13.886844       0.299197   \nstd           0.993958       4.044746      11.971032       0.396901   \nmin           0.000000       0.000000    -120.000000      -4.500000   \n25%           1.000000       1.050000       6.500000       0.000000   \n50%           1.000000       1.960000      10.000000       0.000000   \n75%           1.000000       4.080000      17.000000       0.500000   \nmax           9.000000     117.990000     400.000000       4.500000   \n\n             mta_tax     tip_amount   tolls_amount  ehail_fee  \\\ncount  630918.000000  630918.000000  630918.000000        0.0   \nmean        0.487651       0.864308       0.238420        NaN   \nstd         0.089545       1.681640       1.224454        NaN   \nmin        -0.500000     -10.560000      -5.760000        NaN   \n25%         0.500000       0.000000       0.000000        NaN   \n50%         0.500000       0.000000       0.000000        NaN   \n75%         0.500000       1.460000       0.000000        NaN   \nmax         3.800000     100.000000      95.760000        NaN   \n\n       improvement_surcharge   total_amount   payment_type      trip_type  \\\ncount          630918.000000  630918.000000  630918.000000  630918.000000   \nmean                0.272835      16.073151       1.394243       1.081477   \nstd                 0.090102      12.845226       0.512554       0.273566   \nmin                -0.300000    -120.000000       1.000000       1.000000   \n25%                 0.300000       8.300000       1.000000       1.000000   \n50%                 0.300000      11.800000       1.000000       1.000000   \n75%                 0.300000      18.960000       2.000000       1.000000   \nmax                 0.300000     400.000000       5.000000       2.000000   \n\n       congestion_surcharge  \ncount          84538.000000  \nmean               0.000033  \nstd                0.009458  \nmin                0.000000  \n25%                0.000000  \n50%                0.000000  \n75%                0.000000  \nmax                2.750000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VendorID</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>0.0</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>630918.000000</td>\n      <td>84538.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.851513</td>\n      <td>1.331461</td>\n      <td>109.731544</td>\n      <td>129.135265</td>\n      <td>1.318214</td>\n      <td>3.438878</td>\n      <td>13.886844</td>\n      <td>0.299197</td>\n      <td>0.487651</td>\n      <td>0.864308</td>\n      <td>0.238420</td>\n      <td>NaN</td>\n      <td>0.272835</td>\n      <td>16.073151</td>\n      <td>1.394243</td>\n      <td>1.081477</td>\n      <td>0.000033</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.355582</td>\n      <td>1.099408</td>\n      <td>72.824598</td>\n      <td>76.854829</td>\n      <td>0.993958</td>\n      <td>4.044746</td>\n      <td>11.971032</td>\n      <td>0.396901</td>\n      <td>0.089545</td>\n      <td>1.681640</td>\n      <td>1.224454</td>\n      <td>NaN</td>\n      <td>0.090102</td>\n      <td>12.845226</td>\n      <td>0.512554</td>\n      <td>0.273566</td>\n      <td>0.009458</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-120.000000</td>\n      <td>-4.500000</td>\n      <td>-0.500000</td>\n      <td>-10.560000</td>\n      <td>-5.760000</td>\n      <td>NaN</td>\n      <td>-0.300000</td>\n      <td>-120.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>52.000000</td>\n      <td>62.000000</td>\n      <td>1.000000</td>\n      <td>1.050000</td>\n      <td>6.500000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.300000</td>\n      <td>8.300000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>82.000000</td>\n      <td>129.000000</td>\n      <td>1.000000</td>\n      <td>1.960000</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.300000</td>\n      <td>11.800000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>166.000000</td>\n      <td>193.000000</td>\n      <td>1.000000</td>\n      <td>4.080000</td>\n      <td>17.000000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>1.460000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.300000</td>\n      <td>18.960000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>265.000000</td>\n      <td>265.000000</td>\n      <td>9.000000</td>\n      <td>117.990000</td>\n      <td>400.000000</td>\n      <td>4.500000</td>\n      <td>3.800000</td>\n      <td>100.000000</td>\n      <td>95.760000</td>\n      <td>NaN</td>\n      <td>0.300000</td>\n      <td>400.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>2.750000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can build out a create table schema using `pd.io.sql.get_schema`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"green_tripdata\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"lpep_pickup_datetime\" TEXT,\n",
      "  \"lpep_dropoff_datetime\" TEXT,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"ehail_fee\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"trip_type\" INTEGER,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(taxi_data, name= \"green_tripdata\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see there's some datetime fields that are being flagged up as `TEXT` this is a simple update..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"green_tripdata\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"lpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"lpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"ehail_fee\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"trip_type\" INTEGER,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "taxi_data['lpep_pickup_datetime'] = pd.to_datetime(taxi_data['lpep_pickup_datetime'])\n",
    "taxi_data['lpep_dropoff_datetime'] = pd.to_datetime(taxi_data['lpep_dropoff_datetime'])\n",
    "print(pd.io.sql.get_schema(taxi_data, name= \"green_tripdata\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now to load data into our Postgres Instance, for this we'll be using sqlalchemy (as this is what the DE Zoomcamp is using). I would personally use something more lightweight but this is for the course."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.base.Connection at 0x13c84a940>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://nik:nik@localhost:5432/ny_taxi')\n",
    "engine.connect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_tripdata (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we can format the create statement to the engine\n",
    "print(pd.io.sql.get_schema(taxi_data, name= \"green_tripdata\", con=engine))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we should split up the csv a bit instead of one big dataframe to allow for smoother loading, let's say about 50,000 rows per"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "taxi_data_iter = pd.read_csv('data_in/green_tripdata_2019-01.csv', iterator=True, chunksize=50000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now to load..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from time import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk loaded ... took 3.328 seconds\n",
      "Chunk loaded ... took 3.186 seconds\n",
      "Chunk loaded ... took 3.222 seconds\n",
      "Chunk loaded ... took 3.184 seconds\n",
      "Chunk loaded ... took 3.187 seconds\n",
      "Chunk loaded ... took 3.170 seconds\n",
      "Chunk loaded ... took 3.190 seconds\n",
      "Chunk loaded ... took 3.171 seconds\n",
      "Chunk loaded ... took 3.211 seconds\n",
      "Chunk loaded ... took 3.309 seconds\n",
      "Chunk loaded ... took 3.306 seconds\n",
      "Chunk loaded ... took 3.332 seconds\n",
      "Chunk loaded ... took 2.215 seconds\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m     t_start \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m----> 7\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtaxi_data_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     chunk[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlpep_pickup_datetime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(chunk[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlpep_pickup_datetime\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      9\u001B[0m     chunk[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlpep_dropoff_datetime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(chunk[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlpep_dropoff_datetime\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/working-2RtquDFi-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1698\u001B[0m, in \u001B[0;36mTextFileReader.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1696\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m   1697\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1698\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1699\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m   1700\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/working-2RtquDFi-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1810\u001B[0m, in \u001B[0;36mTextFileReader.get_chunk\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m   1808\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m   1809\u001B[0m     size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnrows \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow)\n\u001B[0;32m-> 1810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/working-2RtquDFi-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1778\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1771\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m     (\n\u001B[1;32m   1775\u001B[0m         index,\n\u001B[1;32m   1776\u001B[0m         columns,\n\u001B[1;32m   1777\u001B[0m         col_dict,\n\u001B[0;32m-> 1778\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/working-2RtquDFi-py3.9/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 230\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    232\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/working-2RtquDFi-py3.9/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:833\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mStopIteration\u001B[0m: "
     ]
    }
   ],
   "source": [
    "taxi_data.head(n=0).to_sql(name=\"green_tripdata\", con=engine, if_exists=\"replace\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    t_start = time()\n",
    "\n",
    "    chunk = next(taxi_data_iter)\n",
    "    chunk['lpep_pickup_datetime'] = pd.to_datetime(chunk['lpep_pickup_datetime'])\n",
    "    chunk['lpep_dropoff_datetime'] = pd.to_datetime(chunk['lpep_dropoff_datetime'])\n",
    "\n",
    "    chunk.to_sql(name=\"green_tripdata\", con=engine, if_exists=\"append\")\n",
    "\n",
    "    t_end = time()\n",
    "    t_diff = t_end - t_start\n",
    "\n",
    "    print(f\"Chunk loaded ... took {t_diff:.3f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So we have an error, but that's because we got to the end of the iterator. As this is a quick and easy kind of thing it really doesn't matter that this isn't 100% bulletproof, the data is in and that's that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now to do the lookup data..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "taxi_lookup = pd.read_csv(\"data_in/taxi+_zone_lookup.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "taxi_lookup.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "taxi_lookup.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As there's only 250 odd rows in here, and no awkward datatypes, we can just shove it into the database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "taxi_lookup.to_sql(name=\"taxi_zone_lookup\", con=engine, if_exists=\"replace\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Homework Time\n",
    "\n",
    "I'll be running the sql queries through pandas, just to keep it all in one notebook\n",
    "\n",
    "--------------------------\n",
    "\n",
    "## Question One\n",
    "\n",
    "How many taxi trips were totally made on January 15?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   count\n0  20530",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20530</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT count(*)\n",
    "FROM green_tripdata\n",
    "WHERE lpep_pickup_datetime::DATE = '20190115'\n",
    "    AND lpep_dropoff_datetime::DATE = '20190115'\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=engine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\n",
    "\n",
    "Which was the day with the largest trip distance Use the pick up time for your calculations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "  lpep_pickup_datetime\n0           2019-01-15",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lpep_pickup_datetime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT lpep_pickup_datetime::DATE\n",
    "FROM green_tripdata\n",
    "ORDER BY trip_distance DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=engine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3\n",
    "\n",
    "In 2019-01-01 how many trips had 2 and 3 passengers?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "   passenger_count  number_of_trips\n0                2             1282\n1                3              254",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passenger_count</th>\n      <th>number_of_trips</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1282</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>254</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT passenger_count, count(*) AS number_of_trips\n",
    "FROM green_tripdata\n",
    "WHERE lpep_pickup_datetime::DATE = '20190101'\n",
    "    AND passenger_count BETWEEN 2 AND 3\n",
    "GROUP BY passenger_count\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=engine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 4\n",
    "\n",
    "For the passengers picked up in the Astoria Zone which was the drop up zone that had the largest tip? We want the name of the zone, not the id."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "    index     Zone                           Zone  tip_amount\n0  506162  Astoria  Long Island City/Queens Plaza        88.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Zone</th>\n      <th>Zone</th>\n      <th>tip_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>506162</td>\n      <td>Astoria</td>\n      <td>Long Island City/Queens Plaza</td>\n      <td>88.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT trips.index, pickup_zones.\"Zone\", dropoff_zones.\"Zone\", trips.tip_amount\n",
    "FROM green_tripdata AS trips\n",
    "    INNER JOIN taxi_zone_lookup AS pickup_zones\n",
    "        ON trips.\"PULocationID\" = pickup_zones.\"LocationID\"\n",
    "    INNER JOIN taxi_zone_lookup AS dropoff_zones\n",
    "        ON trips.\"DOLocationID\" = dropoff_zones.\"LocationID\"\n",
    "WHERE pickup_zones.\"Zone\" = 'Astoria'\n",
    "ORDER BY trips.tip_amount desc\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=engine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
